{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyclingdata/tensorflow_practice_coursera/blob/master/Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "7a5ffab0-70aa-4f26-b105-8fb182354bff"
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87f0cb37-d6fa-4453-f7f8-4122a439ead6"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-24 03:19:51--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.128, 2404:6800:4003:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep   4%[                    ]   4.01M  17.0MB/s               \r        /tmp/incept  28%[====>               ]  24.01M  55.1MB/s               \r       /tmp/incepti  57%[==========>         ]  48.01M  64.9MB/s               \r      /tmp/inceptio  85%[================>   ]  72.01M  73.1MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M  82.2MB/s    in 1.0s    \n",
            "\n",
            "2020-03-24 03:19:52 (82.2 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53860af0-9f9f-4bc0-9160-827606d6b47b"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee92833e-d179-4704-8078-d8049f6eb1e8"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7016eabe-5e9e-4b12-c494-f7777eaa5623"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-24 03:22:10--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.128, 2404:6800:4003:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "\r/tmp/horse-or-human   0%[                    ]       0  --.-KB/s               \r/tmp/horse-or-human  23%[===>                ]  33.26M   166MB/s               \r/tmp/horse-or-human  44%[=======>            ]  64.01M   123MB/s               \r/tmp/horse-or-human  61%[===========>        ]  88.01M   105MB/s               \r/tmp/horse-or-human  83%[===============>    ] 119.55M   115MB/s               \r/tmp/horse-or-human  84%[===============>    ] 120.01M  89.6MB/s               \r/tmp/horse-or-human 100%[===================>] 142.65M   101MB/s    in 1.4s    \n",
            "\n",
            "2020-03-24 03:22:12 (101 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2020-03-24 03:22:14--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 2404:6800:4003:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-03-24 03:22:15 (165 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bb2745b6-632e-4f88-ec59-375417870661"
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses/'\n",
        "train_humans_dir = '/tmp/training/humans/'\n",
        "validation_horses_dir = '/tmp/validation/horses/'\n",
        "validation_humans_dir = '/tmp/validation/humans/'\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_horses_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d6ca46ea-42fb-4410-bfab-0ebf88fd8699"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1db9b256-0ae0-4e82-9e29-217d71463bf0"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 20,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks = [callbacks])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 1/20\n",
            "100/100 - 34s - loss: 0.1951 - acc: 0.9200 - val_loss: 0.1248 - val_acc: 0.9706\n",
            "Epoch 2/20\n",
            "Epoch 1/20\n",
            "100/100 - 25s - loss: 0.0656 - acc: 0.9777 - val_loss: 0.0823 - val_acc: 0.9757\n",
            "Epoch 3/20\n",
            "Epoch 1/20\n",
            "100/100 - 25s - loss: 0.0524 - acc: 0.9824 - val_loss: 0.1901 - val_acc: 0.9646\n",
            "Epoch 4/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0309 - acc: 0.9878 - val_loss: 0.1330 - val_acc: 0.9737\n",
            "Epoch 5/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0255 - acc: 0.9919 - val_loss: 0.0433 - val_acc: 0.9889\n",
            "Epoch 6/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0214 - acc: 0.9934 - val_loss: 0.1034 - val_acc: 0.9757\n",
            "Epoch 7/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0731 - acc: 0.9834 - val_loss: 0.0209 - val_acc: 0.9960\n",
            "Epoch 8/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0340 - acc: 0.9889 - val_loss: 0.0131 - val_acc: 0.9960\n",
            "Epoch 9/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0287 - acc: 0.9929 - val_loss: 0.0528 - val_acc: 0.9858\n",
            "Epoch 10/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0180 - acc: 0.9924 - val_loss: 0.2959 - val_acc: 0.9636\n",
            "Epoch 11/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0234 - acc: 0.9944 - val_loss: 0.2124 - val_acc: 0.9767\n",
            "Epoch 12/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0233 - acc: 0.9909 - val_loss: 0.2039 - val_acc: 0.9777\n",
            "Epoch 13/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0173 - acc: 0.9949 - val_loss: 0.1475 - val_acc: 0.9798\n",
            "Epoch 14/20\n",
            "Epoch 1/20\n",
            "100/100 - 23s - loss: 0.0225 - acc: 0.9934 - val_loss: 0.1630 - val_acc: 0.9798\n",
            "Epoch 15/20\n",
            "Epoch 1/20\n",
            "100/100 - 25s - loss: 0.0182 - acc: 0.9944 - val_loss: 0.0442 - val_acc: 0.9889\n",
            "Epoch 16/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0273 - acc: 0.9919 - val_loss: 0.1317 - val_acc: 0.9838\n",
            "Epoch 17/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0130 - acc: 0.9965 - val_loss: 0.3082 - val_acc: 0.9717\n",
            "Epoch 18/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0111 - acc: 0.9964 - val_loss: 0.3342 - val_acc: 0.9727\n",
            "Epoch 19/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0357 - acc: 0.9930 - val_loss: 0.5343 - val_acc: 0.9504\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "100/100 - 24s - loss: 0.0390 - acc: 0.9909 - val_loss: 0.7368 - val_acc: 0.9545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "5ef8604e-204c-48c6-db46-af44af495fd0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4zgJzv8DkgPQ9nie0x8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}